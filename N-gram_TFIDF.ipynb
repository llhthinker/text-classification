{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discretization(s):\n",
    "    try:\n",
    "        ans = int(float(s))\n",
    "        tmp = max(1, 10**(len(str(ans))-2))\n",
    "#         print(tmp)\n",
    "        return str(ans//tmp * tmp)\n",
    "    except:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12000'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discretization('12323.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851\n",
      "['「', '———', '》），', '）÷（１－', '”，', '）、', '＝（', ':', '→', '℃']\n"
     ]
    }
   ],
   "source": [
    "def load_stopwords(path):\n",
    "    stopwords = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            stopwords.append(line.strip())\n",
    "    return stopwords\n",
    "stopwords_path = './data/stopwords.txt'\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "print(len(stopwords))\n",
    "print(stopwords[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"\n",
    "    载入数据\n",
    "    \"\"\"\n",
    "    data= []\n",
    "    labels = []\n",
    "    max_sentence_len = 0\n",
    "    with open(data_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line_list = line.split('\\t')\n",
    "            one_data = line_list[1].split()\n",
    "            tmp_len = len(one_data)\n",
    "            \n",
    "            if tmp_len > max_sentence_len:\n",
    "                max_sentence_len = tmp_len\n",
    "            if tmp_len > 2000:\n",
    "                for i in range(tmp_len):\n",
    "                    one_data[i] = discretization(one_data[i])\n",
    "                data.append(one_data)\n",
    "                labels.append(int(line_list[2]))\n",
    "        f.close()\n",
    "    print(\"max sentence length: \", max_sentence_len)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sentence length:  34445\n",
      "train data size: 2304\n",
      "Test data size: 576\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./data/seg_train.txt\"\n",
    "texts_data, labels = load_data(data_path)\n",
    "train_len = int(len(texts_data) * 0.8)\n",
    "\n",
    "train_texts = texts_data[:train_len]\n",
    "train_labels = labels[:train_len]\n",
    "print(\"train data size:\", train_len)\n",
    "test_texts = texts_data[train_len:]\n",
    "test_labels = labels[train_len:]\n",
    "print(\"Test data size:\", len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['原', '公诉', '机关', '榆阳区', '人民检察院', '。', '上诉人', '（', '原审', '被告人']\n"
     ]
    }
   ],
   "source": [
    "print(train_texts[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({7: 1261, 6: 426, 5: 212, 3: 135, 2: 89, 8: 75, 1: 53, 4: 53})\n",
      "Counter({7: 354, 6: 81, 5: 47, 3: 26, 8: 25, 2: 19, 4: 15, 1: 9})\n",
      "7 -> Counter({2000: 531, 3000: 251, 4000: 171, 5000: 99, 6000: 49, 7000: 40, 8000: 33, 9000: 23, 12000: 14, 10000: 12, 11000: 12, 14000: 5, 13000: 5, 16000: 3, 15000: 3, 23000: 2, 20000: 1, 17000: 1, 19000: 1, 25000: 1, 22000: 1, 18000: 1, 34000: 1, 27000: 1})\n",
      "2 -> Counter({2000: 59, 3000: 19, 4000: 7, 17000: 1, 7000: 1, 6000: 1, 5000: 1})\n",
      "6 -> Counter({2000: 213, 3000: 101, 4000: 41, 5000: 27, 6000: 11, 8000: 8, 7000: 8, 10000: 3, 13000: 3, 11000: 3, 14000: 2, 17000: 2, 9000: 2, 15000: 1, 12000: 1})\n",
      "5 -> Counter({2000: 115, 3000: 49, 4000: 24, 5000: 10, 6000: 4, 14000: 2, 9000: 2, 11000: 2, 7000: 2, 12000: 1, 8000: 1})\n",
      "3 -> Counter({2000: 82, 3000: 25, 4000: 21, 5000: 3, 6000: 2, 7000: 1, 9000: 1})\n",
      "8 -> Counter({2000: 21, 3000: 14, 4000: 14, 6000: 7, 8000: 5, 5000: 5, 7000: 3, 9000: 2, 16000: 1, 14000: 1, 21000: 1, 11000: 1})\n",
      "1 -> Counter({2000: 28, 3000: 12, 4000: 5, 5000: 4, 6000: 2, 7000: 1, 22000: 1})\n",
      "4 -> Counter({2000: 32, 3000: 14, 4000: 6, 11000: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_labels_counter = Counter(train_labels)\n",
    "print(train_labels_counter)\n",
    "test_labels_counter = Counter(test_labels)\n",
    "print(test_labels_counter)\n",
    "dic = {}\n",
    "\n",
    "for i in range(train_len):\n",
    "    if train_labels[i] not in dic:\n",
    "        dic[train_labels[i]] = [len(train_texts[i])//1000 * 1000]\n",
    "    else:\n",
    "        dic[train_labels[i]].append(len(train_texts[i])//1000 * 1000)\n",
    "\n",
    "for d in dic:\n",
    "    print(d, \"->\", Counter(dic[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '00 人民币', '00 推广', '00 返还', '001x', '001x 汉族', '003x', '003x 信息', '003x 广安', '003x 证据', '005', '005 二包', '005 检材', '00617894', '00617894 不动产', '006a', '006a 1200', '006a u9s006a', '006a 沙发', '006a 销售', '01', '01 武林', '01 消费', '0106125b', '0106125b 0106127b', '0106126b', '0106126b 0106707b', '0106127b', '0106127b 四份', '0106127b 房屋', '01066125b', '01066125b 01066127b', '01066126b', '01066126b 01066707b', '01066127b', '01066127b 作废', '01066707b', '01066707b 01066125b', '0106707b', '0106707b 0106125b', '01193608b', '01193608b 01193609b', '01193609b', '01193609b 01193610b', '01193610b', '01193610b 01193611b', '01193611b', '01193611b 池州', '015', '015 利息', '015 月息', '016', '016 2000', '016 5500', '02', '02 2000', '02 借款', '02 褐色', '02f', '02f 乳化', '02gg', '02gg com', '02w', '02w 合计', '02w 延期', '03', '03 2000', '0324', '0324 64', '037', '037 符合规定', '04', '04 2000', '04 乔某', '04 利率', '04 某丙', '048', '048 dk', '049m', '049m 电动车', '050100c2w', '050100c2w 价值', '050100c2w 充电器', '050200c3w', '050200c3w 手机', '051x', '051x 汉族', '05624537', '05624537 no', '05624538', '05624538 第一', '06', '06 咖啡因', '061', '061 130', '061 2000', '063x', '063x 汉族', '0668862', '0668862 no']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2304, 1607784)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(ngram_range=(1,2), stop_words=stopwords)\n",
    "X_train_counts = count_vect.fit_transform([' '.join(text) for text in train_texts])\n",
    "word = count_vect.get_feature_names()\n",
    "print(word[:100])\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2304, 1607784)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(use_idf = True).fit(X_train_counts)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "[7 7 7 7 7 7 7 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "X_test_counts = count_vect.transform([' '.join(text) for text in test_texts])\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "\n",
    "predicted = clf.predict(X_test_tfidf)\n",
    "print(len(predicted))\n",
    "print(predicted[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61458333333333337"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predicted == test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00         9\n",
      "          2       0.00      0.00      0.00        19\n",
      "          3       0.00      0.00      0.00        26\n",
      "          4       0.00      0.00      0.00        15\n",
      "          5       0.00      0.00      0.00        47\n",
      "          6       0.00      0.00      0.00        81\n",
      "          7       0.61      1.00      0.76       354\n",
      "          8       0.00      0.00      0.00        25\n",
      "\n",
      "avg / total       0.38      0.61      0.47       576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llh/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_labels, predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
